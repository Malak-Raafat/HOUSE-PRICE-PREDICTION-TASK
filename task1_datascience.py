# -*- coding: utf-8 -*-
"""Task1 DataScience.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BUPVumq6_qeBC30bNyBTT62jd_U5vJvr

# **HOUSE PRICE PREDICTION TASK**

# **Important Libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
plt.style.use(['ggplot'])
import pandas as pd
import seaborn as sns
from  warnings import filterwarnings
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error,r2_score
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import GradientBoostingRegressor
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import seaborn as sns
from  warnings import filterwarnings
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error,r2_score

df=pd.read_csv('/content/kc_house_data.csv')
df.head(10)

df.info(verbose=False)

df.info

df.dtypes

nulls = pd.DataFrame({'Null Values': df.isnull().sum(),'% Null Values': df.isnull().sum()*100/len(df) })
nulls

df.isnull().sum()

df.isna().sum()

df.isin(['?']).sum()



df.shape

df.duplicated

df.duplicated().sum()

df.shape





#le=LabelEncoder()
#df['date']=le.fit_transform(df['date'])
#df['date'].dtype

unique_counts = df.nunique()

print("\nNumber of unique values in each column:")
print(unique_counts)

df['date'] = pd.to_datetime(df["date"])

df['year'] = df['date'].apply(lambda df: df.year)
df['month'] = df['date'].apply(lambda df: df.month)

df.dtypes

df[df['bedrooms'] == 0].value_counts().sum()

df['floors'].value_counts().to_frame()

df.columns



sns.displot(df['price'],kde=True)

sns.countplot(data=df,x='bedrooms')

sns.countplot(data=df,x='bathrooms')

plt.figure(figsize=(10,5))
sns.scatterplot(x='price',y='sqft_living',data=df)

plt.figure(figsize=(10,6))
sns.boxplot(data=df,x='bedrooms',y='price')

df.corr(numeric_only=True)['price'].sort_values()

plt.figure(figsize = (12, 6))

sns.distplot(df['price'], color = 'green')
plt.ticklabel_format(style='plain', axis = 'y')

plt.title('Distribution of Price')
plt.xlabel('Price (in millions)')
plt.ylabel('No. of houses (in millions)')

plt.show()

list = df[['price','bedrooms','bathrooms','sqft_living','floors']]
list.hist(color='green')
plt.show()

plt.figure(figsize = (10, 6))
sns.distplot(df["price"])

plt.figure(figsize = (10, 6))
sns.boxplot(x = "month", y = "price", data = df)

sns.boxplot(x = "waterfront", y = 'price', data = df)

df.groupby("year").mean()["price"].plot()

df.groupby("month").mean()["price"].plot()

df.groupby(['year','month'])['price'].mean().plot(kind = 'bar', figsize=(12,8))

df.hist(bins=50,figsize=(15,15))
plt.show()

df.plot(kind="scatter", x="long", y="lat", c="price", cmap="rainbow", s=3, figsize=(12,12))

#determine whether houses with a waterfront view or without a waterfront view have more price outliers.
sns.boxplot(data=df,x=df['waterfront'],y=df['price'])

plt.figure(figsize = (12, 6))

sns.distplot(df['price'], color = 'green')
plt.ticklabel_format(style='plain', axis = 'y')

plt.title('Distribution of Price')
plt.xlabel('Price (in millions)')
plt.ylabel('No. of houses (in millions)')

plt.show()

plt.figure(figsize=(12,10))
sns.histplot(df['price'],kde=True)

#determine if the feature sqft_above is negatively or positively correlated with price.
sns.regplot(data=df,x=df['sqft_above'],y=df['price'])

cor = df.corr()
plt.figure(figsize=(20,15))
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)
plt.show()

corr_matrix = df.corr()
fig, ax = plt.subplots(figsize=(15, 10))
ax = sns.heatmap(corr_matrix,
 annot=True,
linewidths=0.5,
fmt=".2f",
cmap="YlGnBu");
bottom, top = ax.get_ylim()
ax.set_ylim(bottom + 0.5, top - 0.5)

df.drop('price',axis=1).corrwith(df.price).plot(kind='bar',grid=True,figsize=(10,6),title="Correlation of all features with price ")

"""**FEATURE** **SELECTION**"""

drop_col = ['id', 'date','zipcode']
df = df.drop(drop_col, axis=1)
df.head()

df.skew()

# splitting data
X=df.drop(columns='price')
Y=df['price']

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=44)

print(f"the shape of X_train is : {X_train.shape}")
print(f'the shape of X_test is : {X_test.shape}')
print(f'the shape of Y_tain is : {Y_train.shape}')
print(f'the shape of Y_test is {Y_test.shape}')

"""# **RandomForestRegressor with Accuracy 87.8%**"""

# RandomForestRegressor
model1=RandomForestRegressor(n_estimators=200,random_state=5,max_samples=0.9,max_features=0.80,max_depth=30)
model1.fit(X_train,Y_train)
Y_pred_randomforest=model1.predict(X_test)

print(f'Mae is : {mean_absolute_error(Y_test,Y_pred_randomforest)}')
print("Train accuracy",model1.score(X_train,Y_train))
print("Test accuracy",model1.score(X_test,Y_test))

"""# **DecisionTreeRegressor with Accuracy 76.7%**"""

# DecisionTreeRegressor
model2=DecisionTreeRegressor()
model2.fit(X_train,Y_train)
Y_pred_decisiontree=model2.predict(X_test)


print(f'Mae is : {mean_absolute_error(Y_test,Y_pred_decisiontree)}')
print("Train accuracy",model2.score(X_train,Y_train))
print("Test accuracy",model2.score(X_test,Y_test))

"""# **LinearRegression with Accuracy 69%**"""

#LinearRegression
model3=LinearRegression()
model3.fit(X_train,Y_train)
Y_pred_linear=model3.predict(X_test)

print(f'Mae is : {mean_absolute_error(Y_test,Y_pred_linear)}')
print("Train accuray",model3.score(X_train,Y_train))
print("Test accuracy",model3.score(X_test,Y_test))

"""# **GradientBoostingRegressor with Accuracy 89.9%**"""

#gradientBoostingRegressor
model4 = GradientBoostingRegressor(n_estimators=300,max_depth=5,learning_rate = 0.1 ,random_state=33)
model4.fit(X_train, Y_train)
Y_predict_gradient=model4.predict(X_test)

print(f'Mae is : {mean_absolute_error(Y_test,Y_predict_gradient)}')
print("Train accuracy",model4.score(X_train, Y_train))
print("Test accuracy", model4.score(X_test, Y_test))